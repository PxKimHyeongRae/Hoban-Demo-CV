# YOLO Helmet Detection 실험 결과 정리

## 평가 환경
- **평가셋**: go2k_manual (604장, 1,680 bbox)
- **클래스**: person_with_helmet (0), person_without_helmet (1)
- **SAHI 기본 설정**: 1280x720 타일, overlap=0.15, NMS/0.4/IOS, perform_standard_pred=True
- **모델**: YOLOv8 Medium (yolo26m.pt 기반)

## 모델 목록

| 모델 | 학습 데이터 | 학습 해상도 | mAP50 (val) | 비고 |
|------|-----------|-----------|-------------|------|
| v2 | go2k v2 (11,832장) | 640px | 0.925 | 주력 모델 |
| v3 | go2k v2 (11,832장) | 1280px | 0.951 | 고해상도 특화 |
| v5 | go2k v2 (11,832장) | 640px | 0.920 | AdamW + strong aug |

## Phase A: Quick Training 실험 (20 epoch, 3,916장)

v2 하이퍼파라미터가 이미 최적에 가까운지 검증.

| 실험 | 핵심 변경 | mAP50 | mAP50-95 | vs baseline |
|------|----------|-------|----------|-------------|
| A0 baseline | v2 하이퍼파라미터 | 0.894 | 0.631 | - |
| A1 copy_paste | cp=0.4, er=0.3, cm=10 | 0.894 | 0.629 | -0.2%p |
| A2 freeze | freeze=10, lr=0.001 | 0.830 | 0.592 | -6.4%p |
| A3 loss | box=8.5, dfl=2.0, cls=0.5 | 0.894 | 0.633 | +0.2%p |
| A4 strong_aug | scale=0.9, mix=0.2, deg=10 | 0.889 | 0.621 | -1.0%p |

**결론**: v2 하이퍼파라미터가 거의 최적. freeze backbone은 치명적(-6.4%p). loss 비율 미세 조정만 소폭 효과.

## Phase B: 추론 최적화 실험 (재학습 없음)

### B1: 단일 모델 Baseline

| 설정 | TP | FP | FN | Prec | Rec | F1 |
|------|-----|-----|-----|------|-----|-----|
| v2 conf=0.55 | 1571 | 188 | 109 | 0.893 | 0.935 | 0.914 |
| v2 conf=0.60 | 1550 | 161 | 130 | 0.906 | 0.923 | 0.914 |
| v3 conf=0.40 | 1374 | 64 | 306 | 0.955 | 0.818 | 0.881 |
| v5 conf=0.50 | 1518 | 210 | 162 | 0.878 | 0.904 | 0.891 |

### B1: 단일 모델 + Per-class Confidence (Top 5)

| 설정 | TP | FP | FN | Prec | Rec | F1 |
|------|-----|-----|-----|------|-----|-----|
| v2 c0=0.65 c1=0.35 | 1548 | 137 | 132 | 0.919 | 0.921 | 0.920 |
| v2 c0=0.65 c1=0.40 | 1546 | 135 | 134 | 0.920 | 0.920 | 0.920 |
| v2 c0=0.65 c1=0.30 | 1549 | 140 | 131 | 0.917 | 0.922 | 0.920 |
| v2 c0=0.70 c1=0.35 | 1522 | 110 | 158 | 0.933 | 0.906 | 0.919 |
| v2 c0=0.70 c1=0.40 | 1520 | 108 | 160 | 0.934 | 0.905 | 0.919 |

### B2: WBF vs NMS 앙상블 (v2+v3, Top 5)

| 설정 | TP | FP | FN | Prec | Rec | F1 |
|------|-----|-----|-----|------|-----|-----|
| v2+v3 WBF iou=0.4 conf=0.40 | 1545 | 98 | 135 | 0.940 | 0.920 | 0.930 |
| v2+v3 WBF iou=0.5 conf=0.40 | 1544 | 99 | 136 | 0.940 | 0.919 | 0.929 |
| v2+v3 WBF iou=0.6 conf=0.40 | 1534 | 106 | 146 | 0.935 | 0.913 | 0.924 |
| v2+v3 WBF iou=0.4 conf=0.45 | 1493 | 65 | 187 | 0.958 | 0.889 | 0.922 |
| v2+v3 NMS iou=0.4 conf=0.55 | 1591 | 208 | 89 | 0.884 | 0.947 | 0.915 |

**WBF가 NMS 대비 F1 +1.5%p 우위** (0.930 vs 0.915)

### B3: 3-모델 WBF + Per-class Conf (Top 10)

| 설정 | TP | FP | FN | Prec | Rec | F1 |
|------|-----|-----|-----|------|-----|-----|
| **v2+v3+v5 WBF/0.4 c0=0.50 c1=0.30** | **1528** | **70** | **152** | **0.956** | **0.910** | **0.932** |
| v2+v3+v5 WBF/0.4 c0=0.50 c1=0.25 | 1531 | 75 | 149 | 0.953 | 0.911 | 0.932 |
| v2+v3+v5 WBF/0.4 c0=0.50 c1=0.35 | 1520 | 64 | 160 | 0.960 | 0.905 | 0.931 |
| v2+v3+v5 WBF/0.5 c0=0.50 c1=0.30 | 1524 | 70 | 156 | 0.956 | 0.907 | 0.931 |
| v2+v3+v5 WBF/0.5 c0=0.50 c1=0.25 | 1527 | 75 | 153 | 0.953 | 0.909 | 0.931 |
| v2+v3+v5 WBF/0.4 c0=0.50 c1=0.40 | 1515 | 62 | 165 | 0.961 | 0.902 | 0.930 |
| v2+v3+v5 WBF/0.5 c0=0.50 c1=0.35 | 1516 | 64 | 164 | 0.959 | 0.902 | 0.930 |
| v2+v3 WBF iou=0.4 conf=0.40 | 1545 | 98 | 135 | 0.940 | 0.920 | 0.930 |
| v2+v3 WBF iou=0.5 conf=0.40 | 1544 | 99 | 136 | 0.940 | 0.919 | 0.929 |
| v2+v3+v5 WBF/0.5 c0=0.50 c1=0.40 | 1511 | 62 | 169 | 0.961 | 0.899 | 0.929 |

## 최적 설정 요약

### 용도별 추천

| 용도 | 설정 | F1 | Prec | FP |
|------|------|-----|------|-----|
| **최고 F1** | v2+v3+v5 WBF/0.4 c0=0.50 c1=0.30 | 0.932 | 0.956 | 70 |
| **최소 FP (오탐 최소화)** | v2+v3+v5 WBF/0.4 c0=0.50 c1=0.40 | 0.930 | 0.961 | 62 |
| **최고 Recall** | v2+v3+v5 WBF/0.4 c0=0.50 c1=0.25 | 0.932 | 0.953 | 75 |
| **단일 모델 (경량)** | v2 c0=0.65 c1=0.35 | 0.920 | 0.919 | 137 |
| **2-모델 앙상블** | v2+v3 WBF iou=0.4 conf=0.40 | 0.930 | 0.940 | 98 |

### 성능 향상 이력

| 단계 | 설정 | F1 | 향상 |
|------|------|-----|------|
| 초기 baseline | v2 conf=0.55 | 0.914 | - |
| + per-class conf | v2 c0=0.65 c1=0.35 | 0.920 | +0.6%p |
| + 2-모델 WBF | v2+v3 WBF/0.4 conf=0.40 | 0.930 | +1.6%p |
| + 3-모델 WBF + per-class | v2+v3+v5 WBF/0.4 c0=0.50 c1=0.30 | **0.932** | **+1.8%p** |

## 핵심 인사이트

1. **WBF > NMS**: 앙상블에서 WBF가 NMS 대비 F1 +1.5%p 우위. WBF는 중복 박스를 평균하여 좌표 정확도 향상.
2. **3-모델 diversity**: v5(weight=0.5)를 추가하면 v2+v3 대비 +0.2%p. 다양한 학습 설정의 모델이 상호 보완.
3. **Per-class conf 필수**: helmet_on(c0)과 helmet_off(c1)에 다른 threshold 적용이 일관되게 효과적.
4. **v3는 보조 역할**: v3 단독은 Recall 부족(0.818)이지만, v2와 앙상블 시 Precision 보강 역할.
5. **하이퍼파라미터는 포화**: Phase A에서 v2 설정이 이미 최적에 근접함을 확인. 추가 학습 튜닝보다 추론 최적화가 효과적.

## 최적 설정 상세 (배포용)

```python
# 3-모델 WBF 앙상블 설정
models = {
    "v2": "hoban_go2k_v2/weights/best.pt",  # image_size=640
    "v3": "hoban_go2k_v3/weights/best.pt",  # image_size=1280
    "v5": "hoban_go2k_v5/weights/best.pt",  # image_size=640
}

# SAHI 설정
sahi_config = {
    "tile_width": 1280,
    "tile_height": 720,
    "overlap": 0.15,
    "confidence_threshold": 0.05,  # 낮게 설정 후 post-hoc filtering
    "perform_standard_pred": True,
    "postprocess_type": "NMS",
    "postprocess_match_threshold": 0.4,
    "postprocess_match_metric": "IOS",
}

# WBF 앙상블 설정
wbf_config = {
    "iou_thr": 0.4,
    "weights": [1, 1, 0.5],  # v2, v3, v5
    "skip_box_thr": 0.0001,
}

# Per-class confidence thresholds
class_conf = {
    0: 0.50,  # person_with_helmet
    1: 0.30,  # person_without_helmet
}
```
