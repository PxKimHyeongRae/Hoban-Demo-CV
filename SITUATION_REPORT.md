# 현황 보고서: 데이터 오염 문제와 향후 방향

## 작성일: 2026-02-16

---

## 1. 핵심 문제: 평가 데이터 전면 오염

### 발견 사실

수동 라벨링한 CCTV 데이터가 두 종류 있음:

| 데이터셋 | 이미지 수 | 날짜 | 카메라 | 설명 |
|----------|----------|------|--------|------|
| **go2k** | 604장 | 02-11, 02-12 | cam1, cam2 | eval GT로 사용 |
| **3k CVAT** | 2,564장 | 02-10, 02-11, 02-12 | cam1, cam2 | 추가 라벨링 데이터 |

**문제: 3k가 go2k를 거의 포함하고 있음**

```
3k 2,564장
├── 20260210: 223장 (go2k에 없는 고유 데이터)
├── 20260211: 850장 (go2k 02-11과 대부분 겹침)
└── 20260212: 1,491장 (go2k 02-12와 대부분 겹침)

go2k 604장 중 489장(81%)이 3k에도 포함
```

### 모델별 eval leakage 현황

| 모델 | 학습 데이터 출처 | eval 604장 중 leaked | clean | clean GT bbox |
|------|-----------------|---------------------|-------|---------------|
| v2 | go2k 479장 x8 | 479장 (79.3%) | 125장 | 328 |
| v3 | go2k 타일 분할 | 479장 (79.3%) | 125장 | 328 |
| v4 | 3k 223장 x3 | 489장 (80.9%) | 115장 | ~300 |
| v5 | 3k 669장 x3 | 489장 (80.9%) | 115장 | ~300 |
| v6 | go2k (=v2 동일) | 479장 (79.3%) | 125장 | 328 |
| v7 | go2k 166장 x4 | 166장 (27.5%) | 438장 | ~1,200 |

**전 모델에 대해 clean한 이미지: 24장, 2 bbox → 평가 불가능**

### 교차 오염 구조

```
eval 604장 분류:
├── 397장: v2 train에도 있고 3k에도 있음 → 전 모델에 leaked
├──  82장: v2 train에만 있음 → v2/v3/v6에 leaked (v4/v5에는 clean)
├──  92장: 3k에만 있음 → v4/v5에 leaked (v2/v3/v6에는 clean)
├──   9장: v7 train에만 있음
└──  24장: 어디에도 없음 → 2 bbox만 있어서 무의미
```

**결론: 모델 간 공정한 비교 자체가 불가능한 상황.**

---

## 2. 지금까지의 성능 수치 재해석

### 이전에 보고된 수치 (Clean 125장)

| 설정 | 보고 F1 | 실제 의미 |
|------|---------|----------|
| v2 단독 | 0.862 | v2에 대해서만 clean. **신뢰 가능** |
| v3 단독 | 0.858 | v3에 대해서만 clean. **신뢰 가능** |
| v5 단독 | 0.866 | **v5에 대해 73.6% leaked!** 부풀려진 수치 |
| v7 단독 | 0.826 | v7에 대해서만 clean. 신뢰 가능 |
| v3+v5+v7 WBF | 0.904 | **v5 leakage로 오염.** 실제 성능 불명 |
| v2+v3+v5 WBF | 0.891 | **v5 leakage로 오염.** 실제 성능 불명 |

### 신뢰할 수 있는 수치

**v2/v3/v6 단독 (Clean 125장, 328 bbox)** - 이 세 모델은 같은 데이터 사용:
- v2: F1=0.862 (per-class c0=0.60, c1=0.15)
- v3: F1=0.858 (uniform conf=0.30)
- v6: F1=0.817 (학습 부족)

**v7 (Clean 438장)** - 가장 넓은 clean eval:
- v7: F1=0.826 (go2k 166장만으로 학습)

**v4/v5는 별도 clean 115장에서만 신뢰 가능** (v2 clean 125장과 다른 이미지 세트)

### 앙상블: 신뢰 가능한 조합

v5가 포함되지 않은 앙상블만 Clean 125장에서 신뢰 가능:
- v2+v3 WBF: F1=0.886
- v2+v3+v7 WBF: 미측정 (측정 필요)

---

## 3. 각 모델이 실제로 무엇인지

| 모델 | 초기 가중치 | CCTV 데이터 | v13 보조 | 총 train | imgsz | best mAP50 |
|------|-----------|------------|---------|---------|-------|-----------|
| v2 | v13_s2 | go2k 479 x8복사 | 8,000 | 11,832 | 640 | 0.929 |
| v3 | v13_s2 | go2k 타일분할 | 8,000 | 11,872 | **1280** | **0.954** |
| v4 | v13_s2 | 3k 223 x3복사 | 3,000 | ~5,564 | 640 | 0.919 |
| v5 | v13_s2 | 3k 669 x3복사 | 8,000 | ~15,692 | 640 | 0.938 |
| v6 | v13_s2 | go2k (=v2) | 8,000 | 11,832 | 640 | 0.906 |
| v7 | COCO pt | go2k 166 x4증강 | 3,666(필터) | 4,330 | 640 | 0.753 |

### 핵심 관찰

- **x8, x3 복사는 byte 동일** (MD5 검증 완료) → 실질적 데이터 다양성 없음
- **v13 보조 데이터**: bbox가 eval보다 12.8배 큼 → 도메인 불일치
- **v7만 COCO pretrained**: 나머지는 모두 v13_stage2에서 finetune
- **v6은 v2와 동일 데이터**: 하이퍼만 바꿨는데 15에폭에서 early stop → 실패

---

## 4. 근본 원인 정리

### 왜 이렇게 되었나

1. **go2k와 3k가 같은 현장/시간대** 데이터인데 별개로 관리
2. **eval set을 먼저 분리하지 않고** 전부 train에 투입
3. **데이터 복사(x8, x3)가 augmentation이 아닌 byte copy**
4. **v13 보조 데이터가 67%** 차지하면서 도메인 불일치
5. **평가 시 leakage를 뒤늦게 발견** → 교차 오염까지 누적

### 구조적 한계

- **소형 객체**: eval GT의 88.7%가 원본 기준 30px 미만 → 640px에서 ~10px
- **FN의 93%가 30px 미만** → 하이퍼 튜닝이 아닌 해상도/데이터 문제
- **eval 편향**: cam2가 87.7%, 2일 데이터 → 일반화 보장 어려움

---

## 5. 현실적 선택지

### 옵션 A: 평가셋 새로 구성 (즉시 실행 가능)

**방법**: 기존 데이터에서 시간 기반 분리

```
학습용: 02-10 + 02-11 데이터 전부
평가용: 02-12 데이터 중 일부 (새로 라벨링 또는 기존 라벨 활용)
```

**장점**: 추가 라벨링 최소화, 시간 기반이라 temporal leakage 없음
**단점**: 02-12 하루치만 eval → 여전히 다양성 부족

**실행 방안**:
- go2k + 3k 합집합에서 02-12 데이터 추출
- 02-12: ~1,491장 (3k 기준) → 이 중 라벨이 있는 것만 eval로 사용
- 02-10 + 02-11: 나머지 전부 train으로

### 옵션 B: 새 CCTV 데이터 라벨링 (가장 확실)

**방법**: video_indoor_archive에서 새 프레임 추출 → 라벨링

**가용 데이터**:
- /data/video_indoor_archive/20260210_125712/: snapshots 1,542장
- /data/video_indoor_archive/20260211_*/: snapshots 372장
- 원본 영상에서 추가 프레임 추출 가능

**장점**: 완전히 독립적인 eval set, 어떤 모델에도 leaked 아님
**단점**: 수동 라벨링 필요 (시간/비용)

### 옵션 C: K-Fold 방식 (학습 재설계)

**방법**: go2k + 3k 합집합(~2,700 고유)을 K-Fold로 분할

```
Fold 1: 80% train / 20% eval → 모델 A
Fold 2: 다른 80% train / 20% eval → 모델 B
...
전체 평균으로 성능 보고
```

**장점**: 데이터 최대 활용, 통계적으로 견고
**단점**: K번 학습 필요 (시간), 배포 시 어떤 모델을 쓸지 결정 필요

### 옵션 D: Hold-out 확정 후 재학습 (권장)

**방법**:
1. go2k + 3k 합집합에서 **20%를 평가 전용으로 영구 분리** (~540장)
2. 나머지 80%로만 학습 (~2,160장 CCTV + v13 보조)
3. 모든 모델을 동일 조건에서 재학습 & 평가

```
합집합: ~2,700장 고유 CCTV 이미지
├── Train (80%): ~2,160장 (+ v13 보조)
└── Eval (20%):  ~540장 (영구 고정, 절대 학습에 미사용)

분리 방법: 시간 기반 (02-12 오후 등) 또는 랜덤 stratified
```

**장점**:
- 모든 모델을 동일 eval로 공정 비교 가능
- CCTV train 데이터가 기존 479장 → 2,160장으로 4.5배 증가
- leakage 구조적으로 불가능
- 한 번 정리하면 이후 모든 실험이 깨끗함

**단점**: 기존 모델 전부 재학습 필요 (하지만 어차피 오염된 모델이므로)

---

## 6. 권장 실행 계획

### Phase 0: 즉시 - 데이터 정리 (1일)

1. go2k + 3k 합집합 구성 → 고유 이미지 ~2,700장 확인
2. 시간 기반 eval split 결정 (예: 02-12 15시 이후 = eval)
3. Train/Eval 이미지 리스트 확정, 파일로 저장
4. v13 보조 데이터 bbox 크기 필터링 (area 0.0001~0.005)

### Phase 1: 기준 모델 재학습 (1-2일)

1. 새 데이터셋으로 v2 설정 재학습 (baseline)
2. 새 데이터셋으로 v3 설정 재학습 (1280px)
3. Clean eval에서 성능 측정 → 이것이 새 기준선

### Phase 2: 최적화 (2-3일)

1. CCTV 데이터 2,160장 + 실제 augmentation (byte copy 아님)
2. 1280px 학습 + 대량 데이터 결합 (v3 + v5의 장점)
3. 타일 기반 학습으로 소형 객체 강화
4. 앙상블 조합 탐색

### Phase 3: 검증 (1일)

1. 최종 모델을 video archive 새 프레임에서 시각적 검증
2. 배포 설정 확정

---

## 7. 잊지 말아야 할 교훈

1. **eval set은 프로젝트 시작 시 분리하고 절대 건드리지 않는다**
2. **데이터 복사 ≠ augmentation** (byte copy는 다양성 제로)
3. **여러 데이터 소스의 겹침을 반드시 확인한다**
4. **leakage는 성능을 4~9%p 부풀린다** (실측 확인)
5. **v13 보조 데이터는 도메인 필터링 필수** (bbox 12.8배 차이)

---

## 8. 현재 신뢰할 수 있는 것

| 항목 | 상태 |
|------|------|
| v2 Clean 125장 F1=0.862 | 신뢰 가능 (v2/v3/v6 기준) |
| v3 Clean 125장 F1=0.858 | 신뢰 가능 (v2/v3/v6 기준) |
| v2+v3 WBF F1=0.886 | 신뢰 가능 (둘 다 같은 clean set) |
| v5 "Clean" F1=0.866 | **오염됨** (73.6% leaked) |
| v3+v5+v7 WBF F1=0.904 | **오염됨** (v5 포함) |
| 소형 객체가 핵심 병목 | 신뢰 가능 (구조적 사실) |
| WBF > NMS | 신뢰 가능 (같은 조건 비교) |
| Overlap 값은 영향 없음 | 신뢰 가능 |

**현재 확인된 최고 Clean 성능: v2+v3 WBF F1=0.886 (Clean 125장)**
