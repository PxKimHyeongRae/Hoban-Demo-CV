# 개발 일지 — 2026-02-07

## 프로젝트: 공사현장 안전장비 인식 데이터 → 헬멧 학습 데이터셋 구축

**목표:** AIHub 공사현장 안전장비 인식 데이터에서 헬멧 착용/미착용만 분리하여, 향후 object detection 학습에 바로 사용할 수 있는 데이터셋을 만든다.

---

## 이전 작업 (2026-02-06)

### ~20:25~03:16 — 원본 데이터 다운로드
- AIHub에서 공사현장 안전장비 인식 데이터 (Dataset #163) 다운로드
- 경로: `/data/aihub_data/105.공사현장_안전장비_인식_데이터/`
- 공항시설 서측 데이터는 26개 `.part` 분할 파일로 다운로드됨 (AIHub 다운로더 특성)

---

## 2026-02-07 작업

### 13:30~13:50 — 데이터 탐색 및 PDF 분석

**문제:** 원본 데이터는 45개 클래스(안전벨트, 중장비, 구조물 등)가 뒤섞여 있어서, 헬멧만 뽑으려면 먼저 클래스 코드를 정확히 알아야 한다. AIHub 페이지에는 클래스 목록이 상세하게 안 나와 있다.

**과정:**
- 홈 디렉토리의 PDF 2개를 열어봤지만, Python `PyPDF2`로는 텍스트가 추출되지 않았다 (이미지 기반 PDF로 추정)
- `poppler-utils`를 설치하고 `pdftotext`로 텍스트 추출에 성공
- 테크니컬 리포트 PDF에서 **전체 클래스 분류 체계 표**를 발견 — 이것이 핵심이었다

**결정 근거:**
- Class 07 = 안전모 착용, Class 08 = 안전모 미착용으로 확인
- 라벨 JSON의 `class` 필드가 문자열("07")인 것도 확인. 일부 파일에서 int로 저장된 경우도 있을 수 있으므로 `str(cls).zfill(2)` 정규화가 필요하다고 판단

**교훈:** 이 PDF 2개가 없었으면 클래스 매핑을 알 수 없었다. AIHub 데이터는 반드시 함께 제공되는 가이드라인 문서를 먼저 확인해야 한다.

### 13:50~14:00 — 전체 라벨 스캔

**문제:** 19개 라벨 zip (Training 10개 + Validation 9개) 중에서 어떤 zip에 헬멧 데이터가 있는지 모른다. 전수 스캔이 필요했다.

**발견:**
- 7.스튜디오와 9.주상복합에는 헬멧 데이터가 **0건** — 스튜디오는 사다리(22) 위주, 주상복합은 비계(31) 위주였다
- 헬멧 착용은 1,354,120 인스턴스, 미착용은 246,960 인스턴스 → **원본부터 약 5:1 불균형**이 존재
- 이 불균형은 실제 현장 상황을 반영한 것 (대부분 착용, 미착용은 상대적으로 드묾)

### 13:57~14:47 — 전체 헬멧 데이터셋 추출 (약 50분)

**문제:** 원본 데이터가 모두 zip으로 묶여 있고, 라벨과 이미지가 별도 zip에 있다. 라벨 zip 내부 경로와 이미지 zip 내부 경로가 다른 구조라서, 파일명 기반으로 매핑해야 했다.

**해결 과정:**
1. 공항시설 서측 `.part` 26개를 하나의 zip으로 병합 (25.2GB) — 이 과정 없이는 이미지 추출 불가
2. 원천 이미지 zip 45개의 파일 목록을 인덱싱하여 `{파일명: (zip경로, zip내경로)}` 딕셔너리 생성 (1,920,022개)
3. 라벨 zip에서 class 07/08 포함 JSON을 찾아 필터링된 라벨 + 대응 이미지를 추출

**결정 근거:**
- 라벨 JSON에서 class 07/08 외의 annotation은 제거하고, `category` 필드를 추가했다. 원본의 다른 annotation(안전벨트, 중장비 등)은 헬멧 학습에 불필요하므로 노이즈를 줄이기 위함.
- `both` 카테고리(한 이미지에 착용자+미착용자 동시)도 별도 분류. 이진 분류에는 혼란 요소이지만, object detection에는 유용할 수 있어서 제거하지 않고 분류만 해둠.

**결과:** `helmet_dataset/` (487GB) — 전체 753,685개 파일

### 14:47~15:13 — 30K 균형 서브셋 생성

**문제:** 전체 데이터셋이 487GB로 너무 크다. 빠른 실험/프로토타이핑을 위해 적당한 크기의 서브셋이 필요했다.

**결정 근거:**
- **1:1 균형** 선택 이유: 원본이 5:1 불균형이라 그대로 학습하면 미착용 감지 성능이 떨어질 수 있다. 균형 잡힌 서브셋으로 먼저 베이스라인을 잡는 것이 유리하다고 판단.
- **both 제외** 이유: 한 이미지에 착용+미착용이 섞여 있으면 이미지 분류 관점에서 라벨이 모호해진다. 깔끔한 실험을 위해 제외.
- Train/Val 비율은 95:5로 설정 (14,250+750 per class)
- 처음에 symlink로 만들었으나, 이식성을 위해 실제 파일 복사로 재작업

**결과:** `helmet_30k/` (20GB)

### 15:30~16:00 — VFP290K (쓰러진 사람 감지) 데이터셋 조사

**문제:** 쓰러진 사람 감지 모델 학습을 위해 VFP290K 데이터셋을 확보하려 했다.

**과정:**
- GitHub 레포(DASH-Lab/VFP290K) → Google Sites 다운로드 페이지로 연결
- DOI 링크(doi.org/10.23056/VFP300K_DASHLAB)도 같은 페이지로 리다이렉트
- Kaggle, HuggingFace 미러도 검색했으나 없음

**결과:** 직접 다운로드 불가. **이메일 요청 방식만** 제공 (swoo@g.skku.edu, 소속+목적 필요). `/data/fallen/` 폴더만 생성해둔 상태.

**대안으로 확인한 것:**
- Roboflow Fall Detection (4,497장) — 규모가 작음
- falldataset.com (22,636장) — Kinect 센서 기반, 실제 건설현장과 괴리

### 17:30~18:10 — bbox area 기반 필터링 분석

**문제:** 30K 서브셋은 area 필터 없이 랜덤 추출했기 때문에, 이미지 내에서 아주 작은(1~2px) 헬멧도 포함되어 있었다. 학습 품질을 위해 **너무 작은 bbox는 제거**해야 한다는 판단.

**분석 과정:**
- 50,000개 샘플의 bbox area를 이미지 대비 비율(%)로 계산
- **충격적 발견:** median이 0.27%밖에 안 됨. CCTV 광각 영상에서 멀리 있는 사람의 헬멧이라 대부분 매우 작음.
- 착용 2% 기준 적용 시 미착용이 3,182개(21:1 불균형)로 심각하게 줄어듦

**핵심 문제:** 미착용 bbox가 착용보다 전반적으로 더 작다. 동일 기준을 적용하면 미착용 데이터가 극단적으로 부족해진다.

**해결 방향:** 착용과 미착용에 **서로 다른 area 기준** 적용
- 착용 2% + 미착용 2% → 21:1 (사용 불가)
- 착용 2% + 미착용 1.5% → 13:1 (여전히 심함)
- 착용 2% + 미착용 1% → 6:1 (수용 가능)

**결정:** 착용 2%, 미착용 1%를 채택. 미착용이 11,748개로 학습에 의미 있는 양이 되면서, 너무 작은 bbox도 걸러낼 수 있는 절충점.

### 18:10~19:19 — 21K 필터링 서브셋 생성

**결정 근거:**
- 착용 10K + 미착용 10K + 배경 1K = 21K 구성
- **배경 이미지를 포함한 이유:** object detection 모델은 "객체가 없는 이미지"도 학습해야 false positive를 줄일 수 있다. 헬멧 annotation이 있었지만 area 기준 미달로 필터링된 이미지를 배경으로 활용 — 실제 건설현장 배경이라 도메인이 일치한다.
- both 제외 유지

**결과:** `helmet_21k/` (13GB)

### 18:30~19:10 — 미착용 size 분포 심층 분석 및 이상치 조사

**문제:** area 기준 필터링이 아닌, **size 순으로 큰 것부터** 뽑는 방식도 가능하다. 이 경우 30K를 채울 수 있는지, 최소 area가 얼마인지 확인 필요.

**분석:**
- 미착용 전체 246,273 인스턴스를 size 내림차순 정렬
- Top 30K의 최소 area = 0.61% → 1% 보다 작지만 아예 점 수준은 아님
- 이상치 분석: 착용 max=71.43%, 미착용 max=47.93% → 이미지 절반을 차지하는 bbox는 라벨링 오류 가능성

**결정:** 상위 이상치는 20% 이상을 제거. 99.9%ile이 착용 18%, 미착용 7.5%이므로 20%면 극단적 이상치만 잘라내는 보수적 기준.

### 19:10~19:41 — 60K Size 기반 서브셋 생성

**21K와 다른 접근 이유:**
- 21K는 "최소 area 기준 이상인 것 중에서 랜덤"
- 60K는 "area가 큰 순서대로 top N" → **학습 품질이 가장 높은 데이터를 우선 확보**하는 전략
- 미착용을 30K까지 채울 수 있어서 1:1 균형도 달성 가능

**결과:**
- 착용 area 범위: 3.55% ~ 19.99% (꽤 큰 bbox만)
- 미착용 area 범위: 0.43% ~ 19.64% (작은 것도 포함되지만 여전히 상위 12%)
- `helmet_60k/` (36GB)

### 19:29~19:41 — 스크립트 저장 및 문서 정리

**결정:** 매번 인라인 코드로 필터링하지 않도록 범용 스크립트(`extract_helmet_filtered.py`)를 작성. `--wear_min`, `--nowear_min`, `--upper_limit`, `--sort_by` 등 옵션으로 다양한 서브셋을 명령 한 줄로 생성 가능하게 함.

`CONTEXT.md`에 area 분포 통계, 기준별 비교표, 스크립트 사용법을 모두 기록. 다음 작업자가 "왜 이 기준인지"를 이해할 수 있도록.

---

## 최종 산출물 요약

| 파일/폴더 | 용량 | 설명 | 설계 의도 |
|-----------|------|------|-----------|
| `helmet_dataset/` | 487GB | 전체 헬멧 데이터 (753K 파일) | 원본 보존, 이후 필터링의 소스 |
| `helmet_30k/` + `.zip` | 20GB | 1:1 균형, area 필터 없음 | 빠른 프로토타이핑용 |
| `helmet_21k/` + `.zip` | 13GB | 착용2%+미착용1% 필터, 배경 포함 | area 필터로 품질 확보 + 배경 포함 |
| `helmet_60k/` + `.zip` | 36GB | size 내림차순 top 30K씩 | 최고 품질 bbox 우선 선택, 1:1 균형 |
| `extract_helmet_data.py` | — | 원본→helmet_dataset 추출 | 원본 zip에서 전체 추출 재현 |
| `extract_helmet_filtered.py` | — | helmet_dataset→서브셋 범용 필터링 | 다양한 기준으로 서브셋 재생성 |
| `CONTEXT.md` | — | 전체 컨텍스트 문서 | 다음 작업자를 위한 인수인계 |

---

## 핵심 의사결정 로그

| 결정 | 이유 |
|------|------|
| class 07/08 외 annotation 제거 | 헬멧 학습에 불필요한 노이즈 제거 |
| both 카테고리 서브셋에서 제외 | 이진 분류 시 라벨 모호성 방지 |
| 착용/미착용에 서로 다른 area 기준 | 미착용 bbox가 구조적으로 작아서 동일 기준 시 데이터 소실 |
| 이상치 상한 20% | 99.9%ile 기반, 라벨링 오류 의심 데이터 제거 |
| 60K에 size 내림차순 방식 채택 | 학습 품질 우선 확보 + 1:1 균형 달성 |
| 21K에 배경 1K 포함 | false positive 감소를 위한 negative sample |
| symlink 대신 실제 복사 | 이식성 확보 (zip 배포 시 symlink 무용) |

---

## 미해결 사항

1. **VFP290K 데이터셋**: 이메일 요청 필요 (swoo@g.skku.edu) — `/data/fallen/` 폴더만 생성됨
2. **YOLO 포맷 변환**: 아직 미수행. 현재 bbox는 `[x_min, y_min, x_max, y_max]` 절대좌표 → YOLO의 `[cx, cy, w, h]` 정규화좌표로 변환 필요
3. **데이터 불균형**: 원본이 5:1. 서브셋은 1:1로 맞췄으나, 전체 데이터 학습 시 oversampling/augmentation 전략 필요
4. **미착용 bbox가 작은 이유 미규명**: CCTV 각도 문제인지, 라벨링 정책 차이인지 추가 조사 필요
