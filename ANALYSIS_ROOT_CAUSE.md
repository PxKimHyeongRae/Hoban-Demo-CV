# F1=0.932 정체 근본 원인 분석

## 분석 일자: 2026-02-16

---

## CRITICAL 발견 3가지

### 1. Data Leakage (가장 치명적)

Train 원본 479장이 Eval 604장에 **100% 포함** (79.3% 겹침).
현재 F1=0.932는 학습 데이터를 그대로 평가한 수치이며, 실제 일반화 성능은 크게 낮을 가능성이 높다.

- Train go2k 원본: 479장 (cam* 파일)
- Eval go2k_manual: 604장
- 겹치는 이미지: 479장 = eval의 79.3%
- Eval-only (미학습 데이터): 125장

### 2. x1~x7 "증강"이 완전한 동일 복사본

MD5 해시 검증 결과, 원본과 x1~x7이 바이트 단위로 동일.

```
md5sum cam*_8adf88.jpg    = 8cc1fbc04ad21e86dd15ea04a51f75b4
md5sum cam*_8adf88_x1.jpg = 8cc1fbc04ad21e86dd15ea04a51f75b4  (동일!)
```

- 479장 고유 이미지를 8번 반복할 뿐, 실질적 데이터 다양성 없음
- YOLO 내장 augmentation(mosaic, mixup)에만 의존하나 같은 이미지 반복으로 다양성 제한

### 3. Train-Eval 도메인 갭 (bbox 크기 12.8배 차이)

| 데이터 | median bbox area | eval 대비 배율 |
|--------|-----------------|---------------|
| go2k eval GT | 0.000430 | 1.0x (기준) |
| go2k train (cam*) | 0.000434 | ~1.0x (일치) |
| **v13 train (S2-*)** | **0.005486** | **12.8x (불일치)** |

- 학습 데이터의 **67.6%** (8,000/11,832장)가 v13
- v13 bbox가 eval보다 12.8배 큼 → 모델이 큰 객체 위주로 학습

---

## 구조적 문제 상세

### A. 극소형 객체 한계

Eval GT bbox 크기 분포:

| 구간 | bbox 수 | 비율 | 원본 기준 (1920x1080) |
|------|---------|------|----------------------|
| tiny (area < 0.1%) | 1,490 | **88.7%** | median ~30x29px |
| small (0.1~0.5%) | 190 | 11.3% | |
| normal (> 0.5%) | 0 | 0% | |

- 640px 학습 시 30px → ~10px로 축소 (feature map에서 1-2 pixel)
- 15px 미만 bbox 92개(5.5%)는 구조적으로 탐지 불가능
- p10 (하위 10%) bbox는 ~17x17px 수준

### B. 클래스 분포 불일치

| 데이터 | cls0 (착용) | cls1 (미착용) | 비율 (cls0:cls1) |
|--------|-----------|-------------|-----------------|
| Eval | 1,449 | 231 | 6.3:1 |
| go2k 원본 | 1,192 | 160 | 7.5:1 |
| **v13** | **1,543** | **2,158** | **0.7:1 (역전!)** |
| Train 전체 | 11,079 | 3,438 | 3.2:1 |

- v13에서 cls1이 과다 → per-class conf threshold가 필요했던 직접적 원인
- eval에서 cls1은 13.8%에 불과하지만 학습에서는 32.8%

### C. 라벨 불일치

"헬멧_미착용" 이벤트 파일의 라벨 분석:

| 데이터 | 미착용 파일 중 cls=1 없음 | 비율 |
|--------|-------------------------|------|
| Train | 334 / 428 | 78.0% |
| Eval | 408 / 540 | 75.6% |

- 미착용자가 실제로 없는 것인지, 라벨링 누락인지 확인 필요
- 모델이 정당하게 미착용 탐지해도 GT에 없어 FP로 처리될 가능성

### D. WBF 점수 감쇄

| 설정 | FN | 차이 |
|------|-----|------|
| v2 단독 conf=0.40 | ~90 | baseline |
| WBF 3-모델 best | 152 | **+62개 추가 FN** |

- 1개 모델만 탐지(conf=0.8) → WBF 출력 = 0.8×(1/2.5) = 0.32 → cls0 threshold 0.50에서 탈락
- WBF가 FP를 줄이는 대신 Recall을 희생

### E. SAHI 설정 불일치

| 스크립트 | 타일 크기 | overlap | 용도 |
|----------|----------|---------|------|
| eval_go2k_v2.py | 640x640 | 0.2 | 구 평가 |
| eval_phase_b.py | 1280x720 | 0.15 | 현재 평가 |
| detect_go2k_sahi.py | 1280x720 | 0.15 | 배포용 |

- 1280x720 타일은 원본(1920x1080)과 거의 같은 크기 → SAHI의 소형 객체 확대 이점이 미미

### F. 평가셋 대표성 한계

| 항목 | 내용 | 우려 수준 |
|------|------|----------|
| 카메라 분포 | cam2: 530장 (87.7%) | 높음 - 단일 카메라 편향 |
| 날짜 분포 | 2일간 (20260211, 20260212) | 높음 |
| negative 이미지 | 5장 (0.8%) | 높음 - FP 과소 평가 |

### G. IoU=0.5 매칭이 소형 bbox에 과도

| 원본 bbox 크기 | 5px 이동 시 IoU | 8px 이동 시 IoU |
|---------------|----------------|----------------|
| 15x15px | 0.500 (경계) | 0.304 (MISS) |
| 20x20px | 0.600 (OK) | 0.429 (MISS) |
| 30x30px | 0.714 (OK) | 0.579 (OK) |

---

## 핵심 결론

**하이퍼파라미터 튜닝이 무의미한 이유**: 문제는 모델이나 추론 설정이 아니라 데이터 파이프라인의 구조적 결함.

1. 평가 자체가 data leakage로 오염
2. 학습 데이터 67%가 eval 도메인과 불일치
3. 증강이 사실상 미적용
4. 88.7%가 극소형 bbox인데 640px로 학습

---

## 우선순위별 실행 방향

### P0 (즉시 실행)

1. **Data leakage 제거 후 진짜 성능 측정**
   - Eval 604장 중 train과 겹치지 않는 125장에서 F1 재측정
   - 또는 시간 기반 분리 (20260211=train, 20260212=eval)

2. **x1~x7 실제 augmentation 적용 또는 제거**
   - HSV jitter, geometric transform 등 적용한 진짜 augmented copy 생성
   - 또는 오버샘플 제거하고 YOLO 내장 augmentation + class weight에 의존

### P1 (단기 개선)

3. **v13 데이터 bbox 크기 필터링**
   - bbox area가 go2k eval 범위(0.0001~0.005)인 이미지만 선별
   - 또는 v13 비율을 67% → 30% 이하로 축소

4. **타일 기반 학습**
   - 모든 학습 이미지를 640x640 타일로 분할
   - 학습 시 모델이 "보는" 해상도와 SAHI 추론 시 해상도를 동일하게 통일
   - go2k의 30px 객체가 타일 내에서 4.7% vs 원본 1.6%로 상대적 확대

### P2 (중기 개선)

5. **라벨 품질 검수**
   - "헬멧_미착용" 파일 중 cls=1 없는 이미지 시각 확인
   - 라벨 오류 → 수정, 시점 불일치 → 현 라벨 유지

6. **IoU=0.3/0.4로도 평가**
   - 위치 오차 vs 진짜 미탐지 분리하여 에러 원인 정량화

7. **FN 이미지 시각화**
   - 152개 FN의 bbox 크기별/클래스별 분포 직접 분석
   - "탐지 불가능한 GT"와 "탐지 가능했으나 놓친 GT" 분리

### P3 (장기 방향)

8. **모델 아키텍처 개선**
   - YOLO26m의 STAL이 소형 객체에 이점
   - Attention 모듈(CBAM, Triplet Attention) 추가
   - P2 검출 헤드 추가로 소형 객체 feature 강화

9. **Knowledge Distillation**
   - 앙상블(SAHI + WBF) 예측을 pseudo-label로 사용한 self-training
   - 3-모델 앙상블의 지식을 단일 모델에 증류

10. **평가셋 확장**
    - 다양한 카메라/현장/시간대 데이터 추가
    - negative 이미지 비율 확대

---

## SOTA 참고 벤치마크

| 데이터셋 | 최고 모델 | mAP50 | F1 | 환경 |
|----------|-----------|-------|-----|------|
| SHD | YOLOv8-CGS | 93.18% | 92.48% | 통제된 데이터셋 |
| SFCHD (실전) | YOLOv8+SCALE | - | - | 화학 공장 CCTV |
| 현재 프로젝트 | v13 stage2 | 94.5% | - | 건설 현장 CCTV |

현재 mAP50=0.945(v13)는 이미 SOTA급이나, F1=0.932는 data leakage 포함 수치.

---

## Clean Evaluation 결과 (2026-02-16 실측)

### Data Leakage 영향 정량화

| 설정 | Leaked (479장) F1 | Clean (125장) F1 | 차이 |
|------|-------------------|------------------|------|
| v2 단독 conf=0.55 | 0.930 | **0.845** | -8.5%p |
| v2 per-class c0=0.65 c1=0.35 | 0.935 | **0.856** | -7.9%p |
| v2+v3+v5 WBF/0.4 c0=0.50 c1=0.30 | 0.942 | **0.891** | -5.1%p |

**실제 일반화 성능: F1=0.891** (WBF 앙상블, clean 125장 기준)

### Per-class 분석 (Clean, WBF best)

| 클래스 | TP | FP | FN | Prec | Rec | F1 |
|--------|-----|-----|-----|------|-----|-----|
| person_with_helmet | 228 | 19 | 29 | 0.923 | 0.887 | 0.905 |
| person_without_helmet | 57 | 8 | 14 | 0.877 | 0.803 | 0.838 |

### FN 원인: bbox 크기별 분석 (Clean)

| 크기 범주 | GT 수 | FN 수 | Recall |
|-----------|-------|-------|--------|
| tiny (<15px) | 12 | 5 | 0.583 |
| small (15-30px) | 194 | 35 | 0.820 |
| medium (30-50px) | 108 | 3 | 0.972 |
| large (>50px) | 14 | 0 | 1.000 |

FN 43개 중 40개(93%)가 30px 미만. **소형 객체 탐지가 핵심 병목.**

### IoU 민감도 (Clean, WBF best)

| IoU | F1 | 비고 |
|-----|-----|------|
| 0.3 | 0.897 | IoU 완화 시 +0.6%p |
| 0.5 | 0.891 | 기본 |
| 0.6 | 0.878 | 엄격하면 -1.3%p |

IoU 변경 영향 미미 → 위치 오차가 아니라 아예 탐지 못하는 것이 문제.

### v7 (leakage-free 학습) vs v2 비교

v7: go2k 166장 x4 augmented + v13 3666장 (bbox 필터링), eval 438장 (train과 0% 겹침)

| 설정 | v2 Clean F1 | v7 Clean F1 | 차이 |
|------|-------------|-------------|------|
| 단독 conf=0.55 | 0.845 | 0.825 | -2.0%p |
| per-class | 0.856 | 0.817 | -3.9%p |
| +v3+v5 WBF | **0.891** | **0.886** | -0.5%p |

**결론**: v7은 go2k train 166장으로 부족하여 단독 성능 하락.
앙상블에서는 거의 동등 (-0.5%p). x1~x7 byte-copy가 YOLO 런타임 augmentation과
결합하면 완전 무의미하지 않았음 확인.

### 확정된 실제 성능 기준선

| 설정 | 진짜 F1 (Clean 125장) |
|------|----------------------|
| v2 단독 | 0.845 |
| v2 per-class | 0.856 |
| **v2+v3+v5 WBF (최고)** | **0.891** |

향후 모든 실험은 Clean eval (125장) 기준으로 비교해야 함.
