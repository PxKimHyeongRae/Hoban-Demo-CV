# Hoban SAHI F1 돌파 계획 (2026-02-22)

## 1. 실험 전체 요약

### 1.1 모델 버전별 성능

| Version | Model | Params | Data (train) | Start Weights | Epochs | mAP50-95 | SAHI F1 |
|---------|-------|--------|-------------|---------------|--------|----------|---------|
| v17 | yolo26m | 21.8M | 10,564 (v16) | COCO pt | 41 | 0.722 | 0.918 |
| **v19** | yolo26m | 21.8M | **10,852** (v16+helmet_off 88+neg 200) | **v17 best.pt → resume** | 86 | 0.719 | **0.928** |
| v20 | yolo26m | 21.8M | 12,470 (v16+helmet_1k 946+neg_1k 960) | v17 best.pt (fresh) | 100 | **0.725** | 0.915 |
| v21-l | yolo26l | 26.3M | 12,470 (v19 디렉터리 현재 상태) | COCO pt | 68 | 0.723 | 0.923 |
| v22 | yolo26x | 59.0M | 10,564 (v16) | COCO pt | 36 | 0.678 | 0.912 |
| v23 | yolo26m | 21.8M | 4,038 (onsite only, dedup) | COCO pt | 96 | 0.694 | 0.919 |

> **주의**: v19 학습 당시에는 10,852장이었으나, 이후 CVAT 추가 수집분이 같은 소스 디렉터리에
> 추가되면서 현재 datasets_go3k_v19/는 12,470장으로 v20과 동일해짐. v21-l은 이 확장된 상태에서 학습.

### 1.2 추론 시간 실험 (v19 모델)

| 방법 | SAHI F1 | vs baseline |
|------|---------|-------------|
| imgsz=1280 (기본) | 0.929 | - |
| TTA+1280 | 0.925 | -0.4%p |
| TTA+1536 | 0.923 | -0.6%p |
| imgsz=1536 | 0.921 | -0.8%p |
| imgsz=1920 | 0.915 | -1.4%p |

### 1.3 후처리 실험

| 방법 | 결과 |
|------|------|
| min_area sweep (0~1e-4) | 최적: 5e-5 (변경 불필요) |
| SAHI 타일 크기 (960x540, 640x480) | 효과 없음 |
| 앙상블 (v17+v16+v13 NMS/WBF) | 효과 없음 (v17 단독 ≥ 모든 조합) |
| cross_nms + gate + per_class | 이미 최적 |

---

## 2. 핵심 발견

### 2.1 효과가 있었던 것
1. **COCO pretraining** → domain-specific보다 +2%p
2. **1280px 학습** → 640px 대비 큰 개선
3. **SAHI 추론** → F1 +10.8%p (0.804→0.912)
4. **Gate 후처리** → FP -40개 (+0.8%p)
5. **helmet_off + negative 데이터 추가** (v19) → +1.0%p
6. **Data quality 필터링** → +10.2%p mAP50-95

### 2.2 효과가 없었던 것
1. **모델 스케일업** (yolo26l/x) → mAP50-95 천장 ~0.723
2. **고해상도 추론** (1536/1920) → 학습-추론 해상도 불일치로 하락
3. **TTA** → FP 증가, F1 하락
4. **앙상블** → 단독 모델과 동일 또는 하락
5. **데이터 양만 증가** → v20(12,470) > v19(10,852)인데 SAHI F1은 v20이 더 낮음
6. **후처리 파라미터 미세 조정** → 이미 천장

### 2.3 새로 발견된 사실

#### v19 vs v20: 데이터 증가가 SAHI F1에는 역효과
- v19: **10,852장** (v16 10,564 + helmet_off 88 + neg 200), v17 best.pt → resume, 86ep
- v20: **12,470장** (v16 10,564 + helmet_1k 946 + neg_1k 960), v17 best.pt fresh, 100ep
- v20이 데이터 +1,618장, mAP50-95도 더 높지만 (0.725 > 0.719), SAHI F1은 더 낮음 (0.915 < 0.928)
- **차이점 2가지**: (1) 데이터량 (v20이 +1,618장 더 많음), (2) resume 여부 (v19만 resume)
- **결론**: 데이터 양 증가와 resume 효과가 복합적. 단순 데이터 추가는 SAHI F1 개선을 보장하지 않음

> **참고**: 현재 파일시스템에서는 v19 디렉터리에도 나중에 추가된 데이터가 포함되어
> v20과 동일한 12,470장으로 보이지만, v19 학습 당시에는 10,852장이었음.

#### mAP50-95와 SAHI F1의 괴리
- mAP50-95가 높다고 SAHI F1이 높지 않음
- v20: mAP50-95=0.725 (최고) but SAHI F1=0.915
- v19: mAP50-95=0.719 but SAHI F1=0.928 (최고)
- **SAHI 추론에서의 소형 객체 탐지 능력**이 mAP와 다른 차원

#### 외부 데이터의 한계적 기여
- v16 train의 76%가 외부(S2-* AIHub) 데이터
- v23(현장 only 4,038장)이 v17(10,564장)과 F1 거의 동일 (0.919 vs 0.918)
- 외부 8,000장의 실질적 기여가 거의 없음

---

## 3. 미시도 전략 및 우선순위

### Priority 1: 즉시 실행 가능

#### A. v19 배포 전환
- **현황**: v17(F1=0.918) 배포 중, v19(F1=0.928)가 +1.0%p 높음
- **작업**: `video_indoor/app.py`의 `MODEL_PATH`를 v19로 변경
- **리스크**: 동일 아키텍처(yolo26m)이므로 추론 속도 변화 없음
- **소요**: 5분
- **예상 효과**: 즉시 F1 +1.0%p 개선

#### B. v21-l fine-tune (v21-l best.pt 기반)
- **근거**: v21-l(yolo26l, COCO pt)이 F1=0.923으로 v17보다 높음.
  v19의 성공 요인이 fine-tune/resume이었다면, v21-l에도 적용 가능
- **방법**: v21-l/best.pt → lr0=0.001, patience=20, 50 epochs
- **데이터**: v19와 동일 (12,470장) 또는 현장+v19추가 (onsite focused)
- **예상 효과**: F1 0.923 → 0.930+ 가능성
- **소요**: ~6시간

### Priority 2: 높은 가치

#### C. Warm restart 실험 (v19 재현)
- **근거**: v19의 성공 요인 중 하나가 resume(warm restart)일 가능성
- **방법**: v17 best.pt → 50ep 학습 → 중단 → last.pt에서 resume → 50ep 추가
- **데이터**: v19 원래 데이터 (10,852장)
- **목적**: warm restart 효과 검증 + 재현
- **예상 효과**: F1 0.928 재현 또는 초과
- **소요**: ~12시간

#### D. v21-l + warm restart
- **근거**: B + C 조합. 더 큰 모델 + warm restart 효과
- **방법**: v21-l best.pt → 50ep fine-tune → 중단 → resume → 50ep 추가
- **예상 효과**: F1 0.930+ 가능성 (현재 최고 전략)
- **소요**: ~12시간

### Priority 3: 탐색적

#### E. 통계적 유의성 검증
- **근거**: 729장/1,270 GT에서 F1 0.001 차이 = TP ~1개 차이
- **방법**: Bootstrap 95% CI 계산 (1000회 리샘플링)
- **목적**: v17 vs v19 vs v21-l 차이의 유의성 확인
- **소요**: 30분 (스크립트 작성 + 실행)

#### F. 현장 데이터 기반 yolo26l 학습
- **근거**: v23(현장 only 4,038장, yolo26m) = F1=0.919
  외부 데이터 기여 미미 → 현장 데이터만으로 yolo26l 학습
- **방법**: yolo26l COCO pt + v23 데이터 (4,038장)
- **예상**: v21-l(0.923)보다 낮을 가능성 (데이터 부족)
- **소요**: ~8시간

#### G. Confidence Calibration
- **근거**: v19와 v20의 mAP vs SAHI F1 괴리
- **방법**: Temperature scaling 또는 Platt scaling으로 confidence 보정
- **목적**: 후처리 per-class conf 최적화의 안정성 개선
- **소요**: 2시간

### Priority 4: 장기/대규모

#### H. 고품질 현장 데이터 추가 수집
- **근거**: 현재 현장 데이터 ~4,000장. 더 다양한 카메라/환경 필요
- **방법**: 추가 CCTV 설치 현장에서 데이터 수집 + CVAT 라벨링
- **목적**: 도메인 다양성 확보
- **소요**: 수일~수주

#### I. 아키텍처 변경 (RT-DETR 등)
- **근거**: YOLO 계열 내 모든 시도 소진 시
- **리스크**: 전체 파이프라인 재검증 필요 (SAHI, 후처리, 배포)
- **소요**: 1~2주

---

## 4. 추천 실행 순서

```
즉시: A (v19 배포 전환) — 5분
  ↓
1일차: B (v21-l fine-tune) — 6시간
  ↓ (학습 중)
1일차: E (통계적 유의성 검증) — 30분
  ↓
2일차: B 결과 평가
  ↓
  ├─ B 성공 (F1>0.928) → D (v21-l + warm restart) — 12시간
  └─ B 실패 → C (v19 warm restart 재현) — 12시간
      ↓
3일차: 결과 평가 → 최종 배포 모델 결정
```

## 5. 성공 기준

| 기준 | 값 |
|------|-----|
| 1차 목표 | SAHI F1 >= 0.935 |
| 2차 목표 | SAHI F1 >= 0.940 |
| 의미 있는 개선 | F1 차이 >= 0.007 (TP ~9개) |
| 배포 전환 기준 | F1 >= 0.925 + helmet_off F1 >= 0.90 |
| 학습 수렴 판정 | val loss 3ep 증가 추세 or mAP 5ep 내 변동 < 0.002 |

## 6. 미해결 질문

1. v19의 warm restart 효과가 재현 가능한가?
2. yolo26l + fine-tune이 yolo26m + fine-tune보다 SAHI F1에서 우위인가?
3. mAP50-95와 SAHI F1의 괴리 원인은 정확히 무엇인가?
4. 729장 평가셋에서 F1 0.928의 95% CI 범위는?
5. 다른 현장(카메라 위치/해상도 다름)에서도 동일 성능을 기대할 수 있는가?
