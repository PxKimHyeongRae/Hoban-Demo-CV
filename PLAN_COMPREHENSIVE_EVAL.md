# SAHI 정확도 극한 최적화 실험

> 2026-02-15 실험 완료

## 실험 전 상태

| 지표 | 값 |
|------|-----|
| 모델 | go2k_v2 (640px 학습, mAP50=0.925) |
| SAHI 타일 | 1280x720, overlap=0.15 |
| 후처리 | NMS / 0.4 / IOS |
| conf | 0.50 |
| **F1** | **0.912** (P=0.884, R=0.942) |
| FP | 208 / 1,790 예측 |

## 실험 결과

### Phase 1: 모델 교체 (v2 vs v3)

#### 종합 eval 시점 (v3 학습 진행중 checkpoint)

| 모델 | conf | TP | FP | FN | P | R | F1 |
|---|---|---:|---:|---:|---|---|---|
| v2 | 0.45 | 1,506 | 221 | 174 | 0.872 | 0.896 | **0.884** |
| v3 (학습중) | 0.30 | 1,383 | 68 | 297 | 0.953 | 0.823 | 0.883 |

#### v3 학습 완료 후 재평가 (100에폭 수렴, best=epoch47)

v3 학습 결과: mAP50=0.954, mAP50-95=0.714 (v2: 0.925, 0.674)

| 모델 | conf | TP | FP | FN | P | R | F1 |
|---|---|---:|---:|---:|---|---|---|
| **v2 +std_pred** | **0.55** | **1,571** | **188** | **109** | **0.893** | **0.935** | **0.914** |
| v3 (최종) | 0.25 | 1,440 | 94 | 240 | 0.939 | 0.857 | 0.896 |
| v3 +std_pred | 0.25 | 1,440 | 94 | 240 | 0.939 | 0.857 | 0.896 |

- **v3는 학습 완료 후에도 v2보다 F1이 낮음** (0.896 vs 0.914)
- v3 Precision 압도적 (0.939, FP=94) — v2(0.893, FP=188)의 절반
- v3 Recall 부족 (0.857, FN=240) — v2(0.935, FN=109)의 2배
- v3에서 perform_standard_pred 효과 없음 (1280px 학습이라 풀이미지 추가 탐지 없음)
- **원인**: v3 학습 데이터(go2k 타일 ~4K장)가 v2(v13+go2k 12K장)보다 작고 다양성 부족

### Phase 2: Overlap 비율 최적화

- overlap 0.05~0.30 sweep → 최적: overlap=0.05 conf=0.45 (F1=0.884)
- overlap 변경은 유의미한 개선 없음. 기존 0.15 유지.

### Phase 3: Per-Class Confidence

- 최적: cls0=0.50 cls1=0.25 (F1=0.886)
- helmet_on: P=0.872 R=0.913 F1=0.892
- helmet_off: P=0.941 R=0.762 F1=0.842
- helmet_off Recall이 0.762로 낮음 → conf 조정만으로 해결 불가, 데이터 증강 필요

### Phase 4: perform_standard_pred (풀이미지+타일 결합)

| 설정 | TP | FP | FN | P | R | F1 |
|---|---:|---:|---:|---|---|---|
| 타일만 conf=0.50 (baseline) | 1,582 | 208 | 98 | 0.884 | 0.942 | 0.912 |
| **풀이미지+타일 conf=0.55** | **1,571** | **188** | **109** | **0.893** | **0.935** | **0.914** |

- **새로운 최고 F1=0.914** (+0.2%p)
- 풀이미지 추론이 타일 경계 FP를 NMS로 억제 + 큰 객체 안정적 탐지
- 추론 시간 거의 동일 (90s vs 94s)

### Phase 5: 모델 앙상블

| 조합 | conf | P | R | F1 |
|---|---|---|---|---|
| v2+v3 NMS | 0.60 | 0.899 | 0.915 | 0.907 |
| v3+v13 NMS | 0.30 | 0.889 | 0.823 | 0.854 |
| v2+v3+v13 NMS | 0.60 | 0.892 | 0.915 | 0.904 |

- 앙상블은 단일 모델(0.914)보다 낮음. v3의 낮은 Recall이 원인.

### Phase 6: Gate + 1280x720

| 설정 | P | R | F1 | FP |
|---|---|---|---|---:|
| gate c=0.25 r=40 conf=0.45 | 0.928 | 0.888 | 0.908 | 116 |
| gate c=0.25 r=30 conf=0.45 | 0.930 | 0.885 | 0.907 | 112 |

- Gate는 FP를 116까지 줄이지만 Recall 손실로 F1=0.908. perform_standard_pred보다 낮음.
- Precision 우선 시나리오에서는 유효 (P=0.928).

## 최종 채택 설정

| 항목 | 값 |
|------|-----|
| 모델 | `hoban_go2k_v2/weights/best.pt` |
| conf | **0.55** |
| SAHI slice | 1280×720, overlap 0.15 |
| perform_standard_pred | **True** |
| 후처리 | NMS / 0.4 / IOS |
| **F1** | **0.914** |
| **Precision** | **0.893** |
| **Recall** | **0.935** |
| FP | 188 |

## 주요 결론

1. **perform_standard_pred=True가 가장 효과적** — 코드 1줄로 F1 +0.2%p
2. **v3는 학습 완료 후에도 F1 기준 v2보다 낮음** — P=0.939 극도로 높지만 R=0.857 부족
3. **v3 Recall 부족 원인**: 학습 데이터 다양성 부족 (go2k 타일 4K vs v2의 v13+go2k 12K)
4. **앙상블/Gate는 현 시점 비효율** — 단일 모델(0.914)보다 낮음
5. **helmet_off 클래스가 병목** — Recall 0.762, 데이터 증강(copy_paste, 추가 라벨링)이 근본 해결
6. **다음 학습(v4) 방향**: v3 방식(1280px, 타일학습, copy_paste) + v2 데이터(v13 혼합 12K) 결합

## 스크립트: `eval_comprehensive.py`, `eval_v3_sahi.py`
