# v16 실험 결과 보고서

## 작성일: 2026-02-17

---

## 1. 실험 목적

v16 baseline (F1=0.885)을 넘기 위한 체계적 탐색.
Quick Train (20ep)으로 후보를 빠르게 선별하고, 앙상블 조합을 탐색.

---

## 2. Phase A: 학습 변수 실험 (Quick 20ep)

| # | 실험 | 변경점 | F1 | vs Baseline |
|---|------|--------|-----|-------------|
| A5 | **COCO pretrained** | yolov8m.pt에서 시작 | **0.898** | **+0.013** |
| A4 | **imgsz 1280** | 1280px 학습 | **0.892** | **+0.007** |
| - | Baseline v16 | v13_s2, 640px, 100ep | 0.885 | - |
| A2 | v13 4K | v13 8K→4K 축소 | 0.852 | -0.033 |
| A1 | no v13 | CCTV 2,564장만 | 0.851 | -0.034 |
| A3 | v13 filtered | v13 bbox area 필터 | 0.840 | -0.045 |
| A6 | heavy aug | copy_paste=0.3, mixup=0.2 | 0.839 | -0.046 |
| A7 | light aug | mosaic=0.5, mixup=0 | 0.831 | -0.054 |

### 핵심 발견

- **COCO pretrained가 v13_s2 pretrained보다 우수** (20ep 기준 +0.013)
  - v13_s2의 도메인 편향이 오히려 방해가 될 수 있음
- **1280px 학습이 효과적** (+0.007, 20ep에서도 개선)
- **v13 데이터 줄이면 역효과** → v13 8K가 적정 비율
- **augmentation 변경은 역효과** → 기본 설정이 최적

---

## 3. Phase B: 앙상블 실험

| # | 조합 | F1 | vs Baseline |
|---|------|-----|-------------|
| B4 | **v16 + v2 + v3** | **0.928** | **+0.043** |
| B1 | v16 + v2 | 0.922 | +0.037 |
| B5 | v16 + v3 + v5 | 0.922 | +0.037 |
| B2 | v16 + v3 | 0.914 | +0.029 |
| B6 | v16 + A5(COCO pt) | 0.909 | +0.024 |
| B3 | v16 + v5 | 0.906 | +0.021 |

### 핵심 발견

- **v16+v2+v3 WBF 앙상블이 F1=0.928** (baseline 대비 +4.3%p)
- v2가 앙상블에서 가장 큰 기여 (v16+v2=0.922 > v16+v3=0.914)
- 3모델 앙상블이 2모델보다 우수 (0.928 > 0.922)
- 이전 모델들은 학습 데이터가 다르므로 앙상블 다양성에 기여

---

## 4. 전체 순위

```
F1=0.928  B4  v16+v2+v3 WBF         ★ 최고
F1=0.922  B1  v16+v2 WBF
F1=0.922  B5  v16+v3+v5 WBF
F1=0.914  B2  v16+v3 WBF
F1=0.909  B6  v16+A5(COCO) WBF
F1=0.906  B3  v16+v5 WBF
F1=0.898  A5  COCO pretrained 단독   ★ 단독 최고
F1=0.892  A4  1280px 단독
F1=0.885  --  v16 baseline
F1=0.852  A2  v13 4K
F1=0.851  A1  no v13
F1=0.840  A3  v13 filtered
F1=0.839  A6  heavy aug
F1=0.831  A7  light aug
```

---

## 5. 최적 conf 설정

| 설정 | c0 (helmet_on) | c1 (helmet_off) |
|------|---------------|-----------------|
| v16+v2+v3 WBF | 0.35 | 0.45 |
| v16+v2 WBF | 0.55 | 0.35 |
| A5 COCO 단독 | 0.45 | 0.45 |
| A4 1280px 단독 | 0.50 | 0.45 |

---

## 6. 향후 방향

### 즉시 실행 가능
1. **v16+v2+v3 WBF 앙상블 배포** (F1=0.928, 추가 학습 불필요)
2. 배포 시 3모델 추론 → WBF 병합 파이프라인 구성

### Full Training 후보 (100ep)
1. **A5 (COCO pretrained)** → 100ep 학습 시 0.90+ 예상
2. **A4 (1280px)** → 100ep 학습 시 0.90+ 예상
3. 위 두 모델 + v16으로 3모델 앙상블 → 0.93+ 가능성

### 실험 환경
- GPU: RTX 4080 16GB
- 총 소요: ~7시간 (Phase A 6.5h + Phase B 0.5h)
- Eval: 3k val 641장, 1,072 bbox (clean, leakage 없음)
